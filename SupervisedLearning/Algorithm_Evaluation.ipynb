{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error of prediction for multi-target regression\n",
    "Data from \"probabilities-multi-target.txt\" will be compared to \"true-multi-target.txt\" <br/>\n",
    "Algorithm considers true for the attributes which probability is higher than .5 and less than 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function - Mean Squared Error(MSE) and Error of prediction (EoP) Root Mean Squared Error (RMSE) metric\n",
    "Loss: $MSE = \\frac{1}{n} \\sum_i \\sum_j (y_{ij} - \\hat{y}_{ij})^2$ <br/>\n",
    "EoP: $RMSE = \\sqrt{MSE}$ <br/>\n",
    "Where $y_{ij}$ is the actual value of the j-th target for the i-th data point and $\\hat{y}_{ij}$ is the predicted value of the j-th target variable for the i-th data point and $n$ is the number of targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function for sports.csv using MSE: 43.35\n",
      "Error of prediction for sports.csv using RMSE: 6.5840716885526085\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#EoP_MSE_MT_r\n",
    "\n",
    "def Loss_EoP_MSE_MT_r(filePath):\n",
    "    true_matrix = np.loadtxt(fname=\"evaluation-metrics-main/sports.csv\", delimiter=\",\", skiprows=1, usecols=(0, 1, 2))\n",
    "    computed_matrix = np.loadtxt(fname=\"evaluation-metrics-main/sports.csv\", delimiter=\",\", skiprows=1, usecols=(3, 4, 5))\n",
    "    Loss = np.sum((true_matrix - computed_matrix) ** 2) / true_matrix.shape[0]\n",
    "    EoP = np.sqrt(Loss)\n",
    "    return Loss, EoP\n",
    "\n",
    "Loss, EoP = Loss_EoP_MSE_MT_r(\"evaluation-metrics-main/sports.csv\")\n",
    "print(f\"Loss function for sports.csv using MSE: {Loss}\")\n",
    "print(f\"Error of prediction for sports.csv using RMSE: {EoP}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy, precision, recall for multi-class\n",
    "Data from \"probabilities-multi-class.txt\" and \"true-multi-class.txt\"<br/>\n",
    "\n",
    "Definitions\n",
    "<ul>\n",
    "    <li>True positive(TP): the number of instances that are correctly classified as positive for a given class</li>\n",
    "    <li>False positive(FP): the number of instances that are incorrectly classified as positive for a given class</li>\n",
    "    <li>True Negative(TN): the number of instances that are correctly classified as negative for a given class</li>\n",
    "    <li>False negative(FN): the number of instances that are incorrectly classified as negative for a given class</li>\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "Accuracy for class i: The proportion of correctly classified instances for class i to the total number of instances for class i.<br/>\n",
    "Accuracy for class i = $\\frac{TP_i + TN_i}{TP_i + FP_i + TN_i + FN_i} $ <br/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision\n",
    "Precision for class i: The proportion of true positives for class i to the total number of predicted positives for class i.<br/>\n",
    "Precision for class i = $\\frac{TP_i}{TP_i + FP_i}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall\n",
    "Recall for class i: The proportion of true positives for class i to the total number of actual positives for class i.<br/>\n",
    "Recall for class i = $\\frac{TP_i}{TP_i + FN_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For class 0\n",
      "Accuracy = 0.82, Precision = 0.717391304347826, Recall = 0.868421052631579\n",
      "For class 1\n",
      "Accuracy = 0.83, Precision = 0.78125, Recall = 0.7142857142857143\n",
      "For class 2\n",
      "Accuracy = 0.87, Precision = 0.8181818181818182, Recall = 0.6666666666666666\n",
      "For class Daisy\n",
      "Accuracy = 0.4230769230769231, Precision = 0.3333333333333333, Recall = 0.36363636363636365\n",
      "For class Tulip\n",
      "Accuracy = 0.2692307692307692, Precision = 0.125, Recall = 0.2857142857142857\n",
      "For class Rose\n",
      "Accuracy = 0.3076923076923077, Precision = 0.14285714285714285, Recall = 0.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def calc_arrays(computed_line, true_line, TP, FP, TN, FN):\n",
    "    for index in range(len(computed_line)):\n",
    "        if computed_line[index] == 1 and true_line[index] == 1:\n",
    "            TP[index] += 1\n",
    "        if computed_line[index] == 1 and true_line[index] == 0:\n",
    "            FP[index] += 1\n",
    "        if computed_line[index] == 0 and true_line[index] == 0:\n",
    "            TN[index] += 1\n",
    "        if computed_line[index] == 0 and true_line[index] == 1:\n",
    "            FN[index] += 1\n",
    "    return TP, FP, TN, FN\n",
    "\n",
    "def print_ACC_PREC_REC_forClass(Class, TP, FP, TN, FN):\n",
    "    print(f'For class {Class}')\n",
    "    ACC = (TP + TN) / (TP + FP + TN + FN)\n",
    "    PREC = TP / (TP + FP)\n",
    "    REC = TP / (TP + FN)\n",
    "    print(f'Accuracy = {ACC}, Precision = {PREC}, Recall = {REC}')\n",
    "\n",
    "def ACC_PREC_REC(prob_filePath, true_filePath):\n",
    "    prob_file = open(prob_filePath, \"r\") \n",
    "    true_file = open(true_filePath, \"r\") \n",
    "\n",
    "    prob_line = prob_file.readline()\n",
    "    true_line = true_file.readline()\n",
    "    firstIteration = True\n",
    "    noSamples = 0\n",
    "    while prob_line and true_line:\n",
    "        noSamples += 1\n",
    "        prob_line = prob_line.split(\" \")\n",
    "        true_line = true_line.split(\" \")\n",
    "\n",
    "        true_line = [int(i) for i in true_line]\n",
    "        prob_line = [float(i) for i in prob_line]\n",
    "\n",
    "        if firstIteration == True:\n",
    "            firstIteration = False\n",
    "            noClasses = len(prob_line)\n",
    "            # *arrays for the TP/TN/FP/FN values for each class which will be updated while reading from the files\n",
    "            TP = np.zeros(noClasses)\n",
    "            FP = np.zeros(noClasses)\n",
    "            TN = np.zeros(noClasses)\n",
    "            FN = np.zeros(noClasses)\n",
    "\n",
    "        max_prob_index = np.argmax(prob_line)\n",
    "        computed_line = [1 if index == max_prob_index else 0 for index in range(len(prob_line))]\n",
    "\n",
    "        TP, FP, TN, FN = calc_arrays(computed_line, true_line, TP, FP, TN, FN)\n",
    "\n",
    "        prob_line = prob_file.readline()\n",
    "        true_line = true_file.readline()\n",
    "    # print(F'TP = {TP}')\n",
    "    # print(F'TN = {TN}')\n",
    "    # print(F'FP = {FP}')\n",
    "    # print(F'FN = {FN}')\n",
    "    for Class in range(noClasses):\n",
    "        print_ACC_PREC_REC_forClass(Class, TP[Class], FP[Class], TN[Class], FN[Class])\n",
    "\n",
    "def calc_arrays_stringed(computed_line, true_line, classes, TP, FP, TN, FN):\n",
    "    for ClassIndex in range(len(classes)):\n",
    "        current_class = classes[ClassIndex]\n",
    "        for index in range(true_line.shape[0]):\n",
    "            if computed_line[index] == current_class and true_line[index] == current_class:\n",
    "                TP[ClassIndex] += 1\n",
    "            if computed_line[index] == current_class and true_line[index] != current_class:\n",
    "                FP[ClassIndex] += 1\n",
    "            if computed_line[index] != current_class and true_line[index] != current_class:\n",
    "                TN[ClassIndex] += 1\n",
    "            if computed_line[index] != current_class and true_line[index] == current_class:\n",
    "                FN[ClassIndex] += 1\n",
    "    return TP, FP, TN, FN\n",
    "            \n",
    "        \n",
    "\n",
    "def ACC_PREC_REC_2(filePath, classes):\n",
    "    # * for a file \n",
    "    true_line = np.loadtxt(fname=filePath, usecols=(0), skiprows=1, delimiter=\",\", dtype=str)\n",
    "    computed_line = np.loadtxt(fname=filePath, usecols=(1), skiprows=1, delimiter=\",\", dtype=str)\n",
    "    \n",
    "    noClasses = len(classes)\n",
    "\n",
    "    TP = np.zeros(noClasses)\n",
    "    TN = np.zeros(noClasses)\n",
    "    FP = np.zeros(noClasses)\n",
    "    FN = np.zeros(noClasses)\n",
    "\n",
    "    TP, TN, FP, FN = calc_arrays_stringed(computed_line, true_line, classes, TP, FP, TN, FN)\n",
    "    for index in range(noClasses):\n",
    "        print_ACC_PREC_REC_forClass(classes[index], TP[index], FP[index], TN[index], FN[index])\n",
    "\n",
    "ACC_PREC_REC(\"evaluation-metrics-main/probabilities-multi-class.txt\", \"evaluation-metrics-main/true-multi-class.txt\")\n",
    "\n",
    "ACC_PREC_REC_2(\"evaluation-metrics-main/flowers.csv\", classes=[\"Daisy\", \"Tulip\", \"Rose\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Loss for binary classification (Binary Cross-Entropy Loss)\n",
    "Definitions <br/>\n",
    "$N$ - Number of entries <br/>\n",
    "$y_i$ - Actual value of ith entry<br/>\n",
    "$p(y_i)$ - Predicted probability <br/>\n",
    "L = $\\frac{1}{N}\\sum_{i=1}^N-(y_{i} \\times log(p(y_i)) + (1 - y_i) \\times log(1 - p(y_i)))$ <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6923370719995571\n",
      "0.5148514558114434\n",
      "0.5626719394292647\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def LogLoss(prob_filePath, true_filePath):\n",
    "    true_matrix = np.loadtxt(true_filePath)\n",
    "    prob_matrix = np.loadtxt(prob_filePath)\n",
    "\n",
    "    Loss = -(true_matrix * np.log(prob_matrix) + (1 - true_matrix) * np.log(1 - prob_matrix))\n",
    "    return np.mean(Loss)\n",
    "\n",
    "print(LogLoss(\"evaluation-metrics-main/probabilities-binary.txt\", \"evaluation-metrics-main/true-binary.txt\"))\n",
    "print(LogLoss(\"evaluation-metrics-main/probabilities-multi-class.txt\", \"evaluation-metrics-main/true-multi-class.txt\"))\n",
    "print(LogLoss(\"evaluation-metrics-main/probabilities-multi-target.txt\", \"evaluation-metrics-main/true-multi-target.txt\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
